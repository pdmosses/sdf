module generation/docs/gen-markup

imports

  libstratego-lib
  
  libspoofax/analysis/-
  libspoofax/core/-
  libspoofax/resource/-
  libspoofax/term/origin
    
  runtime/analysis/-
  runtime/nabl/-
  runtime/task/-
  runtime/index/-
  runtime/properties/-
  runtime/types/-
  analysis/-
  
  signatures/TemplateLang-sig
  generation/signatures/-

rules // Actions

  // generate-docs-pages: (_, _, _, _, project-path) -> None()
  // - for use as an action in the Spoofax menu
  // - the extension of the selected file determines the source language
  // - generates a docs page from each source file in the enclosing project
  
  generate-docs-pages: (_, _, _, path, project-path) -> None()
    with
      ext := <get-extension> path
    ; file-list := <current-language-source-files; filter(where(has-extension(|ext)))>
    ; ast-list := <map(analyzed-ast)> file-list
    ; ref-to-defs-list := <map(ast-to-ref-to-defs-list); concat> ast-list
    ; cons := <parse-file; collect(?Constructor(_))> $[[project-path]/editor/Colorer.esv]
    ; <zip; map(generate-markup(|project-path, ref-to-defs-list, cons))> (file-list, ast-list)

  test-generate-docs-page: (_, _, _, path, project-path) -> None()
    with
      ext := <get-extension> path
    ; file-list := [$[[project-path]/[path]]]
    ; ast-list := <map(analyzed-ast)> file-list
    ; ref-to-defs-list := <map(ast-to-ref-to-defs-list); concat> ast-list
    ; <WriteToTextFile> ($[[project-path]/ref-to-defs-list.txt], ref-to-defs-list)
    ; cons := <parse-file; collect(?Constructor(_))> $[[project-path]/editor/Colorer.esv]
    ; <zip; map(generate-markup(|project-path, ref-to-defs-list, cons))> (file-list, ast-list)

  // analyzed-ast: File -> AST
  // - for use with languages where name binding is specified in NaBL&TS
  
  // TODO: simplify the definition
  
  analyzed-ast: file -> ast'
    with
      ast := <parse-file-with-current-lang> file
    ; Result([FileResult(_, _, ast', _, _, _)], _, _, _, _) := <editor-analyze> [File(file, ast, 0)]
  
  // collect-ref-to-defs-list: AST -> List(Ref, List(Def))
  // - for use by def-to-refs (not implemented by the NaBL&TS API)
    
  ast-to-ref-to-defs-list = 
      collect(where(is-string; get-use))
    ; !(<id>, <map(use-to-defs)>)
    ; zip

  // generate-file-markup(|project-path): file -> ()
  // - when file is a source file for the current language in the project syntax directory,
  //   parse and analyse the file to obtain an ast, then
  //   create or update a Markdown file in the docs directory
  //   by adding HTML to a copy of the source text

//  generate-file-markup(|project-path, ref-to-defs-list): file -> ()
//    where path := <string-replace(|$[[project-path]/], "")> file 
//    ; <string-starts-with(|"syntax/")> path
//    with ast := <parse-file-with-current-lang> file
//    ; Result([FileResult(file', _, ast', _, _, _)], _, _, _, _) := <editor-analyze> [File(file, ast, 0)]
//    ; <generate-markup(|ref-to-defs-list)> ((), (), ast', path, project-path)
//
//  // generate-markup: (_, _, ast, path, project-path) -> (filename, term)
//  
//  generate-markup: (_, _, ast, path, project-path) -> ($[[project-path]/ref-to-defs-list.aterm], ref-to-defs-list)
//    with ref-to-defs-list := <map(collect-ref-to-defs-list); concat> <current-language-source-files>
////    ; <generate-markup(|ref-to-defs-list)> ((), (), ast, path, project-path)

  // generate-markup(|project-path, ref-to-defs-list): AST -> None()
  // - assumes that the project-clone is at the top level of repo-clone
  // - assumes that the docs directory is at the same level
  // - reads source text from the project file selected by path
  // - generates an HTML div element with markup for the ast and any surrounding tokens
  // - embeds the HTML in the source text for a web page
  // - writes the web page source to the docs directory
    
  generate-markup(|project-path, ref-to-defs-list, cons): (file, ast) -> None()
    with
      path := <string-replace(|$[[project-path]/], "")> file
    ; filename := <base-filename> path
    ; project-name := <base-filename> project-path
    ; project-clone := <local-path> project-path
    ; repo-name := <dirname; base-filename> project-clone
    ; repo-clone := <dirname> project-clone
    ; github-repo := $[metaborg/[repo-name]]
    ; target := $[[repo-clone]/docs/[<language>]/[path].md]
    ; say(!target)
    ; ins := <fopen> (path, "r")
    ; outs := <fopen> (target, "w")
    ; <fputs> (
        ${---
          title: {filename}
          ---
          
          # `{filename}`
          
          :simple-github: [{github-repo}/{project-name}/{path}]
          
          [{github-repo}/{project-name}/{path}]: https://github.com/{github-repo}/blob/master/{project-name}/{path} "The source file on GitHub"
          
          }, outs)
    ; div-start := ${<div class="{<language>}"><table class="highlighttable"><tbody><tr>}
    ; div-end :=   ${</tr></tbody></table></div>}
    ; td-start :=  ${<td class="linenos"><div class="linenodiv"><pre><span></span>}
    ; td-end :=    ${</pre></div></td>}
    ; <fputs> (<concat-strings> [div-start, td-start, <gen-linenos> path, td-end], outs)
    ; <fputs> (
        ${
          <td class="code"><pre><code>}, outs)
    ; <gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list)> (0, ast)
    ; gen-tokens-markup(|ins, outs)
    ; <fputs> (
        ${
          </code></pre></td>{div-end}}, outs)
    ; <fclose> ins
    ; <fclose> outs

rules // Line numbers

  // gen-linenos: path:string -> linenos:string
  // - linenos consists of the line numbers of all the lines in the file at path
  // - each line number is on a separate line, with no spaces

  gen-linenos: path -> <for(prefix-lineno | 1, <count-lines> path) ; reverse; lines> []
   
  prefix-lineno(|n): l -> [<int-to-string> n | l]
  
  count-lines = read-text-file ; get-lines; rtrim(?""); length

rules // Nodes

  // gen-node-markup(|ins:Stream, outs:Stream, repo-name:String, cons:List(Constructor(String))):
  //   (p:Int, node:AST) -> r:Int
  // - assumes that the text before position p (>= 0) in ins has already been marked up
  // - assumes that the source text of node starts at position q >= p
  // - matches and marks up all tokens between p and q, writing them to outs
  // - marks up ast, writing it to outs
  // - the result r is the position of the end of the ast text

  // gen-node-markup embeds a reference node in an <a> element with a link to the corresponding definition
  // - assumes that the name of a reference is a string
  // - links to the first definition of the reference in the first file
   
  gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, node) -> r
    where defs@[def1|_] := <is-string; use-to-defs; sort-by-origin> node
    ; direct-path := <direct-path> (<origin-file> node, <origin-file> def1)
    ; (s, t) := <origin-offset> def1
    ; href := $[[direct-path]#[node]_[s]_[t]]
    ; origin-info := <gen-origin-info> (<origin-file> node, defs)
    ; title := $[Defined at [origin-info]]
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<a href="[href]" title="[title]">], outs)
    ; gen-copy(| ins, outs, <subti> (r, q))
    ; <fputs> ($[</a>], outs)
  
  // gen-node-markup embeds a definition node in a <span> element with an id attribute
  // - assumes that the name of a definition is a string
  // - guarantees that the id is unique on each web page by adding the origin-offset to the name

  gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, node) -> r
    where refs := <is-string; def-to-uses(|ref-to-defs-list); sort-by-origin> node
    ; origin-info := <gen-origin-info> (<origin-file> node, refs)
    ; if <eq> (refs, []) then title := "Not referenced" else title := $[Referenced at [origin-info]] end
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<span id="[node]_[q]_[r]" title="[title]">], outs)
    ; gen-copy(| ins, outs, <subti> (r, q))
    ; <fputs> ($[</span>], outs)
  
  // gen-node-markup copies other strings without markup

  gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, node) -> r
    where <is-string> node
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; gen-copy(| ins, outs, <subti> (r, q))
  
  // gen-node-markup embeds a node to be highlighted in a <span> element with a class attribute
  // - takes the set of constructors for highlighted nodes from editor/Colorer.esv
  // - guarantees to mark up all branches of the node

  gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, node@f#(nodes)) -> r
    where <elem> (Constructor(f), cons)
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<span class="cons_[f]">], outs)
    ; r' := <gen-node-markup-map(|ins, outs, repo-name, cons, ref-to-defs-list)> (q, nodes)
    ; gen-copy(| ins, outs, <subti> (r, r'))
    ; <fputs> ($[</span>], outs)

  // gen-node-markup otherwise generates markup only for the branches of the node
  // - guarantees to mark up all branches of the node
  
  gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, f#(nodes)) -> <gen-node-markup-map(|ins, outs, repo-name, cons, ref-to-defs-list)> (p, nodes)
  
  // gen-node-markup-map generates markup for each node in a list of nodes

  gen-node-markup-map(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, [node | nodes]) -> r
    where q := <gen-node-markup(|ins, outs, repo-name, cons, ref-to-defs-list)> (p, node)
    ; r := <gen-node-markup-map(|ins, outs, repo-name, cons, ref-to-defs-list)> (q, nodes)

  gen-node-markup-map(|ins, outs, repo-name, cons, ref-to-defs-list):
    (p, []) -> p

rules // Tokens

  // gen-tokens-markup(|ins:stream, outs:stream):
  // - reads all remaining chars from ins
  // - forms the corresponding string for displaying those chars in HTML
  // - inserts markup for highllghting all tokens in the string
  // - writes the marked-up string to outs
  
  gen-tokens-markup(|ins, outs) = 
    <fputs> (<gen-fgetcs; map(char-to-html-string); concat-strings; markup-tokens> ins, outs)

  // gen-tokens-markup(|ins:stream, outs:stream, n:int):
  // - reads exactly n chars from ins
  // - otherwise as gen-tokens-markup(|ins, outs)

  gen-tokens-markup(|ins, outs, n) =
    <fputs> (<gen-fgetcs(|n); map(char-to-html-string); concat-strings; markup-tokens> ins, outs)
  
  gen-copy(|ins, outs, n) =
    repeat(<fputs> (<fgetc; char-to-html-string> ins, outs) | n)
  
  gen-fgetcs:
    ins -> [c | cs]
    where c := <fgetc> ins
    ; cs :=  <gen-fgetcs> ins
  
  gen-fgetcs:
    ins -> []
  
  gen-fgetcs(|n):
    ins -> [c | cs]
    where <gti> (n, 0)
    ; c := <fgetc> ins
    ; cs :=  <gen-fgetcs(| <int-dec> n)> ins
  
  gen-fgetcs(|0):
    ins -> []

  char-to-html-string: '&' -> "&amp;"
  char-to-html-string: '<' -> "&lt;"
  char-to-html-string: '>' -> "&gt;"
  char-to-html-string: '\t' -> "        " // 8 spaces (Python-Markdown maps tabs in HTML to 4 spaces)
  char-to-html-string: c -> <implode-string> [c]

  // markup-tokens: html:string -> html':string
  // - adds markup for highlighting all tokens in the html string
  
  markup-tokens: "" -> ""
  
  markup-tokens:
    html -> <conc-strings> (token, tokens)
    where (token, html') := <markup-token> html
    ; tokens := <markup-tokens> html'

  // markup-token: html:string -> (token:string, html':string)
  // - assumes html is non-empty
  // - token is the html markup of the first token in html
  // - html' is the un-markedup rest of html
  // - the order of scanning for specific kinds of token follows JSGLR:
  //   https://github.com/metaborg/jsglr/blob/master/org.spoofax.jsglr/src/org/spoofax/jsglr/client/imploder/TokenKindManager.java
  
  markup-token =
    scan-token(scan-whitespace, id) 
    <+
    scan-token(scan-comment,    markup-token-kind(|"layout"))
    <+
    scan-token(scan-keywords,   markup-token-kind(|"keyword"))
    <+
    scan-token(scan-string-1,   id)
    <+
    scan-token(scan-string-2,   id)
//    <+
//    scan-token(scan-number,     markup-token-kind(|"number"))
    <+
    scan-token(scan-escape,     markup-token-kind(|"string"))
    <+
    scan-token(scan-unknown,    id)
//    <+
//    scan-token(scan-identifier, markup-token-kind(|"identifier"))
//    <+
//    scan-token(scan-operator,   markup-token-kind(|"operator"))
//    <+
//    scan-token(scan-var,        markup-token-kind(|"var"))

  // scan-token(scanner, kinder): html:string -> (token:string, html':string)
  // - assumes scanner: (char*, char*) -> (char*, char*)
  // - assumes kinder: html:string -> token:string
  // - when scanner matches a prefix of html (leaving html'), kinder returns token
  
  scan-token(scanner, kinder):
    html -> (token, html')
    where (scanned-chars, unscanned-chars) := <scanner> ([], <explode-string> html)
    ; token := <reverse; implode-string; kinder> scanned-chars
    ; html' := <implode-string> unscanned-chars
  
  scan-char(p):
    (scanned-chars, [char|unscanned-chars]) -> ([char|scanned-chars], unscanned-chars)
    where <p> char
  
  markup-token-kind(|kind): token -> $[<span class="[kind]">[token]</span>]
  
  scan-whitespace = 
    repeat1( scan-char(?' ' + ?'\n' + ?'\r') ) // '\t' already mapped to spaces

  scan-comment =
    ( scan-char(?'%') ; scan-char(?'%') ; repeat( scan-char(not(?'\n' + ?'\r')) ) )
    +
    ( scan-char(?'%') ; repeat1( scan-char(not(?'%' + ?'\n' + ?'\r'))) ; scan-char(?'%') )
    +
    ( scan-char(?'/') ; scan-char(?'*') ; repeat( scan-comment-char ) ; scan-char(?'*') ; scan-char(?'/') )
    +
    ( scan-char(?'/') ; scan-char(?'/') ; repeat( scan-char(not(?'\n' + ?'\r')) ) )
    
  scan-comment-char =
    scan-char(not(?'*'))
    +
    ( scan-char(?'*') ; try( scan-char( not(?'/') ) ) )
  
  scan-keywords =
    scan-keyword ; repeat( repeat1( scan-char(?' ') ) ; scan-keyword )
  
  scan-keyword =
    scan-char(is-alpha) ; repeat( scan-char(is-alpha + ?'-') )
    +
    scan-char(?'-') ; scan-char(?'C') ; scan-char(?'F')
    +
    scan-char(?'-') ; scan-char(?'L') ; scan-char(?'E') ; scan-char(?'X')
    +
    scan-char(?'-') ; scan-char(?'V') ; scan-char(?'A') ; scan-char(?'R')

  scan-unknown =
    scan-char(?'&') ; repeat1( scan-char(is-lower) ) ; scan-char(?';')
    <+
    scan-char(id)

  scan-escape =
    scan-char(?'\') ; scan-char( not(?'&') )
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'a') ; scan-char(?'m') ; scan-char(?'p') ; scan-char(?';')
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'g') ; scan-char(?'t') ; scan-char(?';')
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'l') ; scan-char(?'t') ; scan-char(?';')

  scan-string-1 =
    scan-char(?'\'') ;
    repeat( scan-string-char-1 ) ;
    scan-char(?'\'')
  
  scan-string-char-1 =
    scan-char(not(?'\'' + ?'\'))
    +
    ( scan-char(?'\') ; scan-char(?'\' + ?'\'' + ?'n' + ?'t') )
    +
    ( scan-char(?'\') ; repeat( scan-char(is-num) | 3 ) )
  
  scan-string-2 =
    scan-char(?'"') ;
    repeat( scan-string-char-2 ) ;
    scan-char(?'"')
  
  scan-string-char-2 =
    scan-char(not(?'"' + ?'\'))
    +
    ( scan-char(?'\') ; scan-char(?'\' + ?'"' + ?'n' + ?'t') )
    +
    ( scan-char(?'\') ; repeat( scan-char(is-num) | 3 ) )

  scan-integer =
    try( scan-char(?'+' + ?'-') ) ; repeat1( scan-char(?is-num) )
   
  scan-number =
    scan-integer ; try( scan-char(?'.') ; repeat1( scan-char(?is-num) ) ; scan-char(?'e') ; scan-integer )

rules // Name binding

  use-to-defs:
    node -> defs
    where
      result := <has-annos; get-annos; fetch-elem(?Use(<id>))> node
    with
      defs := <task-get-results> result

  get-use:
    node -> reference
    where
      reference := <has-annos; get-annos; fetch-elem(?Use(_))> node

  get-def:
    node -> definition
    where
      definition := <has-annos; get-annos; fetch-elem(?Def(_))> node

  def-to-uses(|ref-to-defs-list):
    node -> ref-list
    where
      d := <is-string; get-def; debug(!$[[node]: ])> node
    ; ref-list := <filter(if (!d, Snd); elem then Fst else fail end); make-set> ref-to-defs-list
//    ; refs := <collect(<elem> (d, <Snd>)); map(Fst); make-set> ref-to-defs-list

rules // Multi-file order of definitions of the same name

  sort-by-origin = qsort(origin-lt)
  
  origin-lt: (s1, s2) -> ()
    where (f1, f2) := (<origin-file> s1, <origin-file> s2)
    ; if <eq> (f1, f2)
      then 
        if <eq> (<origin-line> s1, <origin-line> s2)
        then <lt> (<origin-column> s1, <origin-column> s2)
        else <lt> (<origin-line> s1, <origin-line> s2)
        end
      else <string-lt> (f1, f2)
      end
    ; !()

rules // A line for each origin file of the nodes, listing the line numbers of the origins

  gen-origin-info: (path, nodes) -> string
    where files := <map(origin-file); make-set> nodes
    ; string := <map(gen-file-info(|path, nodes)); lines; trim-chars(?' ' + ?'\n')> files
  
  gen-file-info(|path, nodes): file -> 
    <concat-strings>
      [ <direct-path> (path, file), " line "
      | <map(origin-file; not(equal(|file)); !"" <+ origin-line; inc; int-to-string);
         separate-by(|", ")> nodes
      ]
  
rules // Direct path

  // direct-path: (s:string, t:string) -> s:string
  // - eliminates any common prefix of s and t
  // - for each dir in the rest of s, prefixes "../" to the rest of t
  
  direct-path: (source-path, target-path) -> string
    where string := 
      <direct-path> (<string-tokenize(|['/'])> source-path, <string-tokenize(|['/'])> target-path)
  
  direct-path: ([], []) -> ""
  
  direct-path: ([x|s*], [x|t*]) -> <direct-path> (s*, t*)
  
  direct-path: ([_|s*], t*) -> <direct-path> (s*, [".."|t*])
  
  direct-path: ([], t*) -> <separate-by(|"/"); concat-strings> t*

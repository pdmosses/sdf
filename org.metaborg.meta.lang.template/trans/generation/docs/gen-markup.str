module generation/docs/gen-markup

imports

  libstratego-lib
  
  libspoofax/analysis/-
  libspoofax/core/-
  libspoofax/resource/-
  libspoofax/term/origin
    
  runtime/analysis/-
  runtime/nabl/-
  runtime/task/-
  runtime/index/-
  runtime/properties/-
  runtime/types/-
  analysis/-
  
  signatures/TemplateLang-sig
  generation/signatures/-

rules // Actions

  // generate-project-markup: (_, _, _, _, project-path) -> None()
  // - for each source file for the current language in the project syntax directory,
  //   create or update a Markdown file in the docs directory
  //   by adding HTML to a copy of the source text
  
  generate-project-markup: (_, _, _, _, project-path) -> None()
    with file* := <current-language-source-files>
    ; <map(try(generate-file-markup(|project-path)))> file*

  // generate-file-markup(|project-path): file -> ()
  // - when file is a source file for the current language in the project syntax directory,
  //   parse and analyse the file to obtain an ast, then
  //   create or update a Markdown file in the docs directory
  //   by adding HTML to a copy of the source text

  generate-file-markup(|project-path): file -> ()
    where path := <string-replace(|$[[project-path]/], "")> file // <current-language-relative-source-path> file; debug 
    ; <string-starts-with(|"syntax/")> path
    with ast := <parse-file-with-current-lang> file
    ; Result([FileResult(file', _, ast', _, _, _)], _, _, _, _) := <editor-analyze> [File(file, ast, 0)]
    ; <generate-ast-markup> ((), (), ast', path, project-path)

  // generate-ast-markup: (_, _, ast, path, project-path) -> None()
  // - assumes that the project-clone is at the top level of repo-clone
  // - assumes that the docs directory is at the same level
  // - reads source text from the project file selected by path
  // - generates an HTML div element with markup for the ast and any surrounding tokens
  // - embeds the HTML in the source text for a web page
  // - writes the web page source to the docs directory
  
  generate-ast-markup: (_, _, ast, path, project-path) -> None()
    with filename := <base-filename> path
    ; project-name := <base-filename> project-path
    ; project-clone := <local-path> project-path
    ; repo-name := <dirname; base-filename> project-clone
    ; repo-clone := <dirname> project-clone
    ; github-repo := $[https://github.com/metaborg/[repo-name]]
    ; github-file := $[[github-repo]/blob/master/[project-name]/[path]]
    ; target := $[[repo-clone]/docs/[<language>]/[path].md]
    ; say(!target)
    ; ins := <fopen> (path, "r")
    ; outs := <fopen> (target, "w")
    ; <fputs> (
        ${---
          title: {filename}
          ---
          
          # `{filename}`
          
          This web page was generated by [_Spoofax_](https://spoofax.dev) from [_raw code_ on _GitHub_]({github-file}).
          
          <div class="{<language>}"><pre><code>}, outs)
    ; _ := <gen-node-markup(|ins, outs, repo-name)> (0, ast)
    ; gen-tokens-markup(|ins, outs)
    ; <fputs> (
        $[
          </code></pre></div>], outs)
    ; <fclose> ins
    ; <fclose> outs

rules // Nodes

  // gen-node-markup(|ins:stream, outs:stream, repo-name:string): (p:int, node:ast) -> r:int
  // - assumes that the text before position p (>= 0) in ins has already been marked up
  // - assumes that the source text of node starts at position q >= p
  // - matches and marks up all tokens between p and q, writing them to outs
  // - marks up ast, writing it to outs
  // - the result r is the position of the end of the ast text

  // gen-node-markup embeds a reference node in an <a> element with a link to the corresponding definition
  // - assumes that the name of a references is a string
   
  gen-node-markup(|ins, outs, repo-name):
    (p, node) -> r
    where definition := <is-string; use-to-def> node
    ; (s, t) := <origin-offset> definition
    ; (q, r) := <origin-offset> node
    ; target-path := <origin-file> definition
    ; source-path := <origin-file> node
    ; direct-path :=
        <direct-path> (<string-tokenize(|['/'])> source-path, <string-tokenize(|['/'])> target-path)
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<a href="[direct-path]#[node]_[s]_[t]">], outs)
    ; gen-copy(| ins, outs, <subti> (r, q))
    ; <fputs> ($[</a>], outs)
  
  // gen-node-markup embeds a definition node in a <span> element with an id attribute
  // - assumes that the name of a definition is a string
  // - guarantees that the id is unique on each web page by adding the origin-offset to the name

  gen-node-markup(|ins, outs, repo-name):
    (p, node) -> r
    where def_ := <is-string; get-def> node
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<span id="[node]_[q]_[r]">], outs)
    ; gen-copy(| ins, outs, <subti> (r, q))
    ; <fputs> ($[</span>], outs)
  
  // gen-node-markup embeds a node to be highlighted in a <span> element with a class attribute
  // - takes the set of constructors for highlighted nodes from editor/Colorer.esv
  // - guarantees to mark up all branches of the node

  gen-node-markup(|ins, outs, repo-name):
    (p, node@f#(node*)) -> r
    where < ?String(_)
          + ?Constructor(_)
          + ?Lit(_)
          + ?CiLit(_)
          + ?Quoted(_)
          + ?Unquoted(_)
          + ?PosRef(_)
          + ?LiteralRef(_)
          + ?LabelRef(_)> node
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<span class="cons_[f]">], outs)
    ; r' := <gen-node-markup-map(|ins, outs, repo-name)> (q, node*)
    ; gen-copy(| ins, outs, <subti> (r, r'))
    ; <fputs> ($[</span>], outs)

  gen-node-markup(|ins, outs, repo-name):
    (p, node@f#(node*)) -> r
    where < ?Regular(_)
          + ?Binary(_)
          + ?Octal(_)
          + ?Decimal(_)
          + ?Hexadecimal(_)> node
    ; (q, r) := <origin-offset> node
    ; gen-tokens-markup(| ins, outs, <subti> (q, p))
    ; <fputs> ($[<span class="cons_[f]">], outs)
    ; gen-copy(| ins, outs, <subti> (r, q))
    ; <fputs> ($[</span>], outs)
  
  // gen-node-markup otherwise generates markup only for the branches of the node
  // - guarantees to mark up all branches of the node
  
  gen-node-markup(|ins, outs, repo-name):
    (p, f#(node*)) -> <gen-node-markup-map(|ins, outs, repo-name)> (p, node*)
  
  // gen-node-markup-map generates markup for each node in a list of nodes

  gen-node-markup-map(|ins, outs, repo-name):
    (p, [node | node*]) -> r
    where q := <gen-node-markup(|ins, outs, repo-name)> (p, node)
    ; r := <gen-node-markup-map(|ins, outs, repo-name)> (q, node*)

  gen-node-markup-map(|ins, outs, repo-name):
    (p, []) -> p

rules // Tokens

  // gen-tokens-markup(|ins:stream, outs:stream):
  // - reads all remaining chars from ins
  // - forms the corresponding string for displaying those chars in HTML
  // - inserts markup for highllghting all tokens in the string
  // - writes the marked-up string to outs
  
  gen-tokens-markup(|ins, outs) = 
    <fputs> (<gen-fgetcs; map(char-to-html-string); concat-strings; markup-tokens> ins, outs)

  // gen-tokens-markup(|ins:stream, outs:stream, n:int):
  // - reads exactly n chars from ins
  // - otherwise as gen-tokens-markup(|ins, outs)

  gen-tokens-markup(|ins, outs, n) =
    <fputs> (<gen-fgetcs(|n); map(char-to-html-string); concat-strings; markup-tokens> ins, outs)
  
  gen-copy(|ins, outs, n) =
    repeat(<fputs> (<fgetc; char-to-html-string> ins, outs) | n)
  
  gen-fgetcs:
    ins -> [c | c*]
    where c := <fgetc> ins
    ; c* :=  <gen-fgetcs> ins
  
  gen-fgetcs:
    ins -> []
  
  gen-fgetcs(|n):
    ins -> [c | c*]
    where <gti> (n, 0)
    ; c := <fgetc> ins
    ; c* :=  <gen-fgetcs(| <int-dec> n)> ins
  
  gen-fgetcs(|0):
    ins -> []

  char-to-html-string: '&' -> "&amp;"
  char-to-html-string: '<' -> "&lt;"
  char-to-html-string: '>' -> "&gt;"
  char-to-html-string: '\t' -> "        " // 8 spaces (Python-Markdown maps tabs in HTML to 4 spaces)
  char-to-html-string: c -> <implode-string> [c]

  // markup-tokens: html:string -> html':string
  // - adds markup for highlighting all tokens in the html string
  
  markup-tokens: "" -> ""
  
  markup-tokens:
    html -> <conc-strings> (token, tokens)
    where (token, html') := <markup-token> html
    ; tokens := <markup-tokens> html'

  // markup-token: html:string -> (token:string, html':string)
  // - assumes html is non-empty
  // - token is the html markup of the first token in html
  // - html' is the un-markedup rest of html
  // - the order of scanning for specific kinds of token follows JSGLR:
  //   https://github.com/metaborg/jsglr/blob/master/org.spoofax.jsglr/src/org/spoofax/jsglr/client/imploder/TokenKindManager.java
  
  markup-token =
    scan-token(scan-whitespace, id) 
    <+
    scan-token(scan-comment,    markup-token-kind(|"layout"))
    <+
    scan-token(scan-keywords,   markup-token-kind(|"keyword"))
    <+
    scan-token(scan-string-1,   id)
    <+
    scan-token(scan-string-2,   id)
//    <+
//    scan-token(scan-number,     markup-token-kind(|"number"))
    <+
    scan-token(scan-escape,     markup-token-kind(|"string"))
    <+
    scan-token(scan-unknown,    id)
//    <+
//    scan-token(scan-identifier, markup-token-kind(|"identifier"))
//    <+
//    scan-token(scan-operator,   markup-token-kind(|"operator"))
//    <+
//    scan-token(scan-var,        markup-token-kind(|"var"))

  // scan-token(scanner, kinder): html:string -> (token:string, html':string)
  // - assumes scanner: (char*, char*) -> (char*, char*)
  // - assumes kinder: html:string -> token:string
  // - when scanner matches a prefix of html (leaving html'), kinder returns token
  
  scan-token(scanner, kinder):
    html -> (token, html')
    where (scanned-char*, unscanned-char*) := <scanner> ([], <explode-string> html)
    ; token := <reverse; implode-string; kinder> scanned-char*
    ; html' := <implode-string> unscanned-char*
  
  scan-char(p):
    (scanned-char*, [char|unscanned-char*]) -> ([char|scanned-char*], unscanned-char*)
    where <p> char
  
  markup-token-kind(|kind): token -> $[<span class="[kind]">[token]</span>]
  
  scan-whitespace = 
    repeat1( scan-char(?' ' + ?'\n' + ?'\r') ) // '\t' already mapped to spaces

  scan-comment =
    ( scan-char(?'%') ; scan-char(?'%') ; repeat( scan-char(not(?'\n' + ?'\r')) ) )
    +
    ( scan-char(?'%') ; repeat1( scan-char(not(?'%' + ?'\n' + ?'\r'))) ; scan-char(?'%') )
    +
    ( scan-char(?'/') ; scan-char(?'*') ; repeat( scan-comment-char ) ; scan-char(?'*') ; scan-char(?'/') )
    +
    ( scan-char(?'/') ; scan-char(?'/') ; repeat( scan-char(not(?'\n' + ?'\r')) ) )
    
  scan-comment-char =
    scan-char(not(?'*'))
    +
    ( scan-char(?'*') ; try( scan-char( not(?'/') ) ) )
  
  scan-keywords =
    scan-keyword ; repeat( repeat1( scan-char(?' ') ) ; scan-keyword )
  
  scan-keyword =
    scan-char(is-alpha) ; repeat( scan-char(is-alpha + ?'-') )
    +
    scan-char(?'-') ; scan-char(?'C') ; scan-char(?'F')
    +
    scan-char(?'-') ; scan-char(?'L') ; scan-char(?'E') ; scan-char(?'X')
    +
    scan-char(?'-') ; scan-char(?'V') ; scan-char(?'A') ; scan-char(?'R')

  scan-unknown =
    scan-char(?'&') ; repeat1( scan-char(is-lower) ) ; scan-char(?';')
    <+
    scan-char(id)

  scan-escape =
    scan-char(?'\') ; scan-char( not(?'&') )
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'a') ; scan-char(?'m') ; scan-char(?'p') ; scan-char(?';')
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'g') ; scan-char(?'t') ; scan-char(?';')
    <+
    scan-char(?'\') ; scan-char(?'&') ; scan-char(?'l') ; scan-char(?'t') ; scan-char(?';')

  scan-string-1 =
    scan-char(?'\'') ;
    repeat( scan-string-char-1 ) ;
    scan-char(?'\'')
  
  scan-string-char-1 =
    scan-char(not(?'\'' + ?'\'))
    +
    ( scan-char(?'\') ; scan-char(?'\' + ?'\'' + ?'n' + ?'t') )
    +
    ( scan-char(?'\') ; repeat( scan-char(is-num) | 3 ) )
  
  scan-string-2 =
    scan-char(?'"') ;
    repeat( scan-string-char-2 ) ;
    scan-char(?'"')
  
  scan-string-char-2 =
    scan-char(not(?'"' + ?'\'))
    +
    ( scan-char(?'\') ; scan-char(?'\' + ?'"' + ?'n' + ?'t') )
    +
    ( scan-char(?'\') ; repeat( scan-char(is-num) | 3 ) )

  scan-integer =
    try( scan-char(?'+' + ?'-') ) ; repeat1( scan-char(?is-num) )
   
  scan-number =
    scan-integer ; try( scan-char(?'.') ; repeat1( scan-char(?is-num) ) ; scan-char(?'e') ; scan-integer )

//  scan-identifier =
//    scan-char(is-alpha) ; repeat( scan-char(is-alphanum + ?'-' + ?'_') )
//
//  scan-operator =
//    repeat1( scan-char(not(is-alpha)) ) // ...
//
//  scan-literal = fail

rules // Name binding

  use-to-def:
    node -> definition
    where
      result := <has-annos; get-annos; fetch-elem(?Use(<id>))> node
    with
      definition := <task-get-results; Hd> result

  get-def:
    node -> definition
    where
      definition := <has-annos; get-annos; fetch-elem(?Def(_))> node

//  use-to-defs:
//    node -> definitions
//    where
//      result := <has-annos; get-annos; fetch-elem(?Use(<id>))> node
//    with
//      definitions := <task-get-results; Hd; index-get-all-values> result

rules // Direct path

  // direct-path: (s*:string*, t*:string*) -> s:string
  // - eliminates any common prefix of s* and t*
  // - for each s in the rest of s*, prefixes ".." to the rest of t*
  // - separates the resulting t* by "/" and concatenates them
  
  direct-path: ([], []) -> ""
  
  direct-path: ([x|s*], [x|t*]) -> <direct-path> (s*, t*)
  
  direct-path: ([_|s*], t*) -> <direct-path> (s*, [".."|t*])
  
  direct-path: ([], t*) -> <separate-by(|"/"); concat-strings> t*
